---
title: Unsupervised embedding of trajectories captures the latent structure of mobility
authors:
- Dakota Murray
- Jisung Yoon
- Sadamori Kojaku
- Rodrigo Costas
- Woo-Sung Jung
- Staša Milojević
- Yong-Yeol Ahn

author_notes:
- 'Equal contribution'
- 'Equal contribution'
- 'Equal contribution'


date: '2020-01-01'
publishDate: '2023-11-02T20:37:11.362851Z'
publication_types:
- article-journal
publication: '*arXiv preprint arXiv:2012.02785*'

url_pdf: 'https://arxiv.org/abs/2012.02785'

abstract: Human migration and mobility drives major societal phenomena including epidemics, economies, innovation, and the diffusion of ideas. Although human mobility and migration have been heavily constrained by geographic distance throughout the history, advances and globalization are making other factors such as language and culture increasingly more important.Advances in neural embedding models, originally designed for natural language, provide an opportunity to tame this complexity and open new avenues for the study of migration. Here, we demonstrate the ability of the model word2vec to encode nuanced relationships between discrete locations from migration trajectories, producing an accurate, dense, continuous, and meaningful vector-space representation. The resulting representation provides a functional distance between locations, as well as a digital double that can be distributed, re-used, and itself interrogated to understand the many dimensions of migration. We show that the unique power of word2vec to encode migration patterns stems from its mathematical equivalence with the gravity model of mobility. Focusing on the case of scientific migration, we apply word2vec to a database of three million migration trajectories of scientists derived from the affiliations listed on their publication records. Using techniques that leverage its semantic structure, we demonstrate that embeddings can learn the rich structure that underpins scientific migration, such as cultural, linguistic, and prestige relationships at multiple levels of granularity.Our results provide a theoretical foundation and methodological framework for using neural embeddings to represent and understand migration both within and beyond science.

summary: We show that the word embedding technique word2vec is mathematically equivalent to the gravity law of mobility, making it ideal for learning dense representations from migration data that can be distributed, re-used, and studied. By treating locations analogously to words and trajectories to sentences,we demonstrate the power of word2vec by applying it to the case of scientists' migrations, for which it encodes information about culture, geography, and prestige at multiple layers of granularity. Our results lay a theoretical and methodological foundation for the application of neural embeddings to the study of migration.


featured: true

image:
  caption: 'Figs from paper'
  focal_point: ''
  preview_only: false



---
